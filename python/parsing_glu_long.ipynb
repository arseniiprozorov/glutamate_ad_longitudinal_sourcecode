{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the sample file\n",
    "file_path = r\"D:\\01-Raw_data-spectro\\Precuneus\\3100205_255881_V17S\\first_run_data\\fit_tissue_adjusted\\summary.csv\"\n",
    "\n",
    "# Load and display the data\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE FILE STRUCTURE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nFile: {file_path}\\n\")\n",
    "\n",
    "# Read the CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\\n\")\n",
    "\n",
    "print(\"Column names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"First few rows:\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Full data:\")\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbdeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parse glutamate spectroscopy data from Precuneus folder\n",
    "Creates one output file with all participants and their metabolite measurements\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "PRECUNEUS_FOLDER = r\"D:\\01-Raw_data-spectro\\Precuneus\"\n",
    "OUTPUT_FILE = r\"c:\\Users\\okkam\\Documents\\GitHub\\glutamate_ad_longitudinal_sourcecode\\precuneus_metabolite_data.csv\"\n",
    "\n",
    "# Metabolites to extract (in order)\n",
    "METABOLITES = ['Glu', 'GABA', 'Gly', 'NAA', 'Cr', 'Cr+PCr', 'GPC', 'PCh', 'mI']\n",
    "\n",
    "# Columns to extract for each metabolite (in order)\n",
    "COLUMNS = ['mM', '/Cr+PCr', '%CRLB', 'SNR', 'FWHM']\n",
    "\n",
    "\n",
    "def extract_participant_data(summary_file_path, participant_id):\n",
    "    \"\"\"\n",
    "    Extract metabolite data from a single participant's summary.csv file\n",
    "    \n",
    "    Args:\n",
    "        summary_file_path: Path to the summary.csv file\n",
    "        participant_id: Participant folder name (e.g., 3100205_255881_V17S)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with participant data\n",
    "    \"\"\"\n",
    "    # Read the summary file\n",
    "    df = pd.read_csv(summary_file_path)\n",
    "    \n",
    "    # Initialize result dictionary with participant ID\n",
    "    result = {'Participant_ID': participant_id}\n",
    "    \n",
    "    # Extract data for each metabolite\n",
    "    for metabolite in METABOLITES:\n",
    "        # Find the row for this metabolite\n",
    "        metabolite_row = df[df['Metab'] == metabolite]\n",
    "        \n",
    "        if len(metabolite_row) == 0:\n",
    "            # Metabolite not found - fill with NaN\n",
    "            for column in COLUMNS:\n",
    "                result[f'{metabolite}_{column}'] = None\n",
    "        else:\n",
    "            # Extract each column value\n",
    "            for column in COLUMNS:\n",
    "                result[f'{metabolite}_{column}'] = metabolite_row[column].values[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_all_participants():\n",
    "    \"\"\"\n",
    "    Parse all participants in the Precuneus folder\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with all participants' data\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # Get all participant folders in Precuneus\n",
    "    precuneus_path = Path(PRECUNEUS_FOLDER)\n",
    "    \n",
    "    if not precuneus_path.exists():\n",
    "        print(f\"ERROR: Precuneus folder not found at {PRECUNEUS_FOLDER}\")\n",
    "        return None\n",
    "    \n",
    "    # Iterate through all participant folders\n",
    "    participant_folders = [f for f in precuneus_path.iterdir() if f.is_dir()]\n",
    "    \n",
    "    print(f\"Found {len(participant_folders)} participant folders\")\n",
    "    print(\"Processing participants...\\n\")\n",
    "    \n",
    "    for participant_folder in participant_folders:\n",
    "        participant_id = participant_folder.name\n",
    "        \n",
    "        # Construct path to summary.csv\n",
    "        summary_path = participant_folder / \"first_run_data\" / \"fit_tissue_adjusted\" / \"summary.csv\"\n",
    "        \n",
    "        if summary_path.exists():\n",
    "            try:\n",
    "                # Extract data for this participant\n",
    "                participant_data = extract_participant_data(summary_path, participant_id)\n",
    "                all_data.append(participant_data)\n",
    "                print(f\"✓ Processed: {participant_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error processing {participant_id}: {e}\")\n",
    "        else:\n",
    "            print(f\"✗ Summary file not found for {participant_id}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if len(all_data) > 0:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Successfully processed {len(all_data)} participants\")\n",
    "        print(f\"{'='*80}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data was extracted!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the parsing\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"PRECUNEUS METABOLITE DATA PARSER\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nSource folder: {PRECUNEUS_FOLDER}\")\n",
    "    print(f\"Output file: {OUTPUT_FILE}\")\n",
    "    print(f\"\\nMetabolites: {', '.join(METABOLITES)}\")\n",
    "    print(f\"Columns per metabolite: {', '.join(COLUMNS)}\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Parse all participants\n",
    "    df = parse_all_participants()\n",
    "    \n",
    "    if df is not None:\n",
    "        # Save to CSV\n",
    "        df.to_csv(OUTPUT_FILE, index=False)\n",
    "        print(f\"\\n✓ Data saved to: {OUTPUT_FILE}\")\n",
    "        print(f\"\\nOutput shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"\\n✗ No output file created\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parse glutamate spectroscopy data from ACC folder\n",
    "Creates one output file with all participants and their metabolite measurements\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "PRECUNEUS_FOLDER = r\"D:\\01-Raw_data-spectro\\ACC\"\n",
    "OUTPUT_FILE = r\"c:\\Users\\okkam\\Documents\\GitHub\\glutamate_ad_longitudinal_sourcecode\\precuneus_metabolite_data.csv\"\n",
    "\n",
    "# Metabolites to extract (in order)\n",
    "METABOLITES = ['Glu', 'GABA', 'Gly', 'NAA', 'Cr', 'Cr+PCr', 'GPC', 'PCh', 'mI']\n",
    "\n",
    "# Columns to extract for each metabolite (in order)\n",
    "COLUMNS = ['mM', '/Cr+PCr', '%CRLB', 'SNR', 'FWHM']\n",
    "\n",
    "\n",
    "def extract_participant_data(summary_file_path, participant_id):\n",
    "    \"\"\"\n",
    "    Extract metabolite data from a single participant's summary.csv file\n",
    "    \n",
    "    Args:\n",
    "        summary_file_path: Path to the summary.csv file\n",
    "        participant_id: Participant folder name (e.g., 3100205_255881_V17S)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with participant data\n",
    "    \"\"\"\n",
    "    # Read the summary file\n",
    "    df = pd.read_csv(summary_file_path)\n",
    "    \n",
    "    # Initialize result dictionary with participant ID\n",
    "    result = {'Participant_ID': participant_id}\n",
    "    \n",
    "    # Extract data for each metabolite\n",
    "    for metabolite in METABOLITES:\n",
    "        # Find the row for this metabolite\n",
    "        metabolite_row = df[df['Metab'] == metabolite]\n",
    "        \n",
    "        if len(metabolite_row) == 0:\n",
    "            # Metabolite not found - fill with NaN\n",
    "            for column in COLUMNS:\n",
    "                result[f'{metabolite}_{column}'] = None\n",
    "        else:\n",
    "            # Extract each column value\n",
    "            for column in COLUMNS:\n",
    "                result[f'{metabolite}_{column}'] = metabolite_row[column].values[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_all_participants():\n",
    "    \"\"\"\n",
    "    Parse all participants in the Precuneus folder\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with all participants' data\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # Get all participant folders in Precuneus\n",
    "    precuneus_path = Path(PRECUNEUS_FOLDER)\n",
    "    \n",
    "    if not precuneus_path.exists():\n",
    "        print(f\"ERROR: Precuneus folder not found at {PRECUNEUS_FOLDER}\")\n",
    "        return None\n",
    "    \n",
    "    # Iterate through all participant folders\n",
    "    participant_folders = [f for f in precuneus_path.iterdir() if f.is_dir()]\n",
    "    \n",
    "    print(f\"Found {len(participant_folders)} participant folders\")\n",
    "    print(\"Processing participants...\\n\")\n",
    "    \n",
    "    for participant_folder in participant_folders:\n",
    "        participant_id = participant_folder.name\n",
    "        \n",
    "        # Construct path to summary.csv\n",
    "        summary_path = participant_folder / \"first_run_data\" / \"fit_tissue_adjusted\" / \"summary.csv\"\n",
    "        \n",
    "        if summary_path.exists():\n",
    "            try:\n",
    "                # Extract data for this participant\n",
    "                participant_data = extract_participant_data(summary_path, participant_id)\n",
    "                all_data.append(participant_data)\n",
    "                print(f\"✓ Processed: {participant_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error processing {participant_id}: {e}\")\n",
    "        else:\n",
    "            print(f\"✗ Summary file not found for {participant_id}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if len(all_data) > 0:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Successfully processed {len(all_data)} participants\")\n",
    "        print(f\"{'='*80}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data was extracted!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the parsing\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"PRECUNEUS METABOLITE DATA PARSER\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nSource folder: {PRECUNEUS_FOLDER}\")\n",
    "    print(f\"Output file: {OUTPUT_FILE}\")\n",
    "    print(f\"\\nMetabolites: {', '.join(METABOLITES)}\")\n",
    "    print(f\"Columns per metabolite: {', '.join(COLUMNS)}\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Parse all participants\n",
    "    df = parse_all_participants()\n",
    "    \n",
    "    if df is not None:\n",
    "        # Save to CSV\n",
    "        df.to_csv(OUTPUT_FILE, index=False)\n",
    "        print(f\"\\n✓ Data saved to: {OUTPUT_FILE}\")\n",
    "        print(f\"\\nOutput shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"\\n✗ No output file created\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
